{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "input_target_list_pkl = 'data/input_taget_list.pkl'\n",
    "\n",
    "\n",
    "class RecLSTM:\n",
    "    def __init__(self, num_items, num_seqs=64, num_steps=50,\n",
    "              lstm_size=128, num_layers=2, learning_rate=0.001,\n",
    "              grad_clip=5, train_keep_prob=0.5):\n",
    "        self.num_items = num_items\n",
    "        self.num_seqs = num_seqs\n",
    "        self.num_steps = num_steps\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_layers = num_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.grad_clip = grad_clip\n",
    "        self.train_keep_prob = train_keep_prob\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.build_inputs()\n",
    "        self.build_lstm()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def build_inputs(self):\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.inputs = tf.placeholder(tf.int32, shape=(\n",
    "                self.num_seqs, self.num_steps), name='inputs')\n",
    "            self.targets = tf.placeholder(tf.int32, shape=(\n",
    "                self.num_seqs, self.num_steps), name='targets')\n",
    "            self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "            # TODO num_items?\n",
    "            self.lstm_inputs = tf.one_hot(self.inputs, self.num_items)\n",
    "            \n",
    "        \n",
    "    def build_lstm(self):\n",
    "        def get_a_cell(lstm_size, keep_prob):\n",
    "            lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "            drop = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "            return drop\n",
    "        \n",
    "        with tf.name_scope('lstm'):\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                [get_a_cell(self.lstm_size, self.keep_prob) for _ in range(self.num_layers)]\n",
    "            )\n",
    "            self.initial_state = cell.zero_state(self.num_seqs, tf.float32)\n",
    "            \n",
    "            self.lstm_output, self.final_state = tf.nn.dynamic_rnn(cell, self.lstm_inputs,\n",
    "                                                                  initial_state=self.initial_state)\n",
    "            seq_output = tf.concat(self.lstm_output, 1)\n",
    "            x = tf.reshape(seq_output, [-1, self.lstm_size])\n",
    "            \n",
    "            with tf.variable_scope('softmax'):\n",
    "                softmax_w = tf.Variable(tf.truncated_normal([self.lstm_size, self.num_items], stddev=0.1))\n",
    "                softmax_b = tf.Variable(tf.zeros(self.num_items))\n",
    "                \n",
    "            self.logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "            self.proba_prediction = tf.nn.softmax(self.logits, name='predictions')\n",
    "            \n",
    "            \n",
    "    def build_loss(self):\n",
    "        with tf.name_scope('loss'):\n",
    "            y_one_hot = tf.one_hot(self.targets, self.num_items)\n",
    "            y_reshaped = tf.reshape(y_one_hot, self.logits.get_shape())\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits,labels=y_reshaped)\n",
    "            self.loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        \n",
    "    def build_optimizer(self):\n",
    "        # use clipping gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), self.grad_clip)\n",
    "        train_op = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "        \n",
    "    def train(self, batch_generator, max_steps, save_path, save_every_n, log_every_n):\n",
    "        self.session = tf.Session()\n",
    "        with self.session as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            step = 0\n",
    "            new_state = sess.run(self.initial_state)\n",
    "            for x, y in batch_generator:\n",
    "                step += 1\n",
    "                start = time.time()\n",
    "                feed = {self.inputs: x,\n",
    "                        self.targets: y,\n",
    "                        self.keep_prob: self.train_keep_prob,\n",
    "                        self.initial_state: new_state}\n",
    "                batch_loss, new_state, _ = sess.run([self.loss,\n",
    "                                                     self.final_state,\n",
    "                                                     self.optimizer],\n",
    "                                                    feed_dict=feed)\n",
    "                end = time.time()\n",
    "                if step % log_every_n == 0:\n",
    "                    print('step: {}/{}... '.format(step, max_steps),\n",
    "                          'loss: {:.4f}... '.format(batch_loss),\n",
    "                          '{:.4f} sec/batch'.format((end - start)*10))\n",
    "                if step % save_every_n == 0:\n",
    "                   self.saver.save(sess, os.path.join(save_path, 'lstm_model'), global_step=step)\n",
    "                if step >= max_steps:\n",
    "                    break\n",
    "            self.saver.save(sess, os.path.join(save_path, 'lstm_model'), global_step=step)\n",
    "\n",
    "            \n",
    "    def test(self, test_generator, item_size, max_steps=100):\n",
    "        with open(input_target_list_pkl, 'rb') as rf:\n",
    "            input_target_list = pickle.load(rf)\n",
    "        input_target_map = dict()\n",
    "        for item in input_target_list:\n",
    "            item_convert = [str(i) for i in item]\n",
    "            key = '|'.join(item_convert[:-1])\n",
    "            value = item[-1]\n",
    "            input_target_map[key] = value\n",
    "        step = 0\n",
    "        sess = self.session\n",
    "        new_state = sess.run(self.initial_state)\n",
    "        hit = 0\n",
    "        li = list()\n",
    "        for i in test_generator:\n",
    "            step += 1\n",
    "            pred_index = 0\n",
    "            key = ''\n",
    "            for item_id in i[0]:\n",
    "#                 print(item_id)\n",
    "                if item_id != 0:\n",
    "                    pred_index += 1\n",
    "                    key = key + str(item_id) + '|'\n",
    "                else:\n",
    "                    break\n",
    "            key = key[:-1]\n",
    "            pred_index = pred_index - 1\n",
    "            feed = {self.inputs: i,\n",
    "                    self.keep_prob: 1,\n",
    "                    self.initial_state: new_state}\n",
    "            preds, new_state = sess.run([self.proba_prediction, self.final_state],\n",
    "                                        feed_dict=feed)\n",
    "            print('----------------input----------------')\n",
    "            print(i[0])\n",
    "            print('----------------output---------------')\n",
    "            print(np.argmax(preds[pred_index]))\n",
    "            pred_output = preds[pred_index][np.argmax(preds[pred_index])]\n",
    "            print('pred_output: {}'.format(pred_output))\n",
    "            print('----------------truth----------------')\n",
    "            print(input_target_map[key])\n",
    "            pred_truth = preds[pred_index][int(input_target_map[key])]\n",
    "            print(pred_truth)\n",
    "            bigger_num = 0\n",
    "            for pred in preds[pred_index]:\n",
    "                if pred > pred_truth:\n",
    "                    bigger_num += 1\n",
    "            print('{} bigger than pred_truth'.format(bigger_num))\n",
    "            li.append(bigger_num)\n",
    "            if np.argmax(preds[pred_index]) == input_target_map[key]:\n",
    "                hit += 1\n",
    "            if step >= max_steps:\n",
    "                break\n",
    "        print(hit)\n",
    "        li.sort()\n",
    "        print(li)\n",
    "\n",
    "    \n",
    "    def load(self, checkpoint):\n",
    "        self.session = tf.Session()\n",
    "        self.saver.restore(self.session, checkpoint)\n",
    "        print('Restored from: {}'.format(checkpoint))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
